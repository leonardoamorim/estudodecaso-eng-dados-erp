{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformando os dados\n",
    "\n",
    "No passo anterior nós criamos as Delta Tables e as salvamos no HDFS.\n",
    "Entretanto esses dados não estão no formato ideal para realizar as análises.\n",
    "Os tipos dos dados também não estão apropriados pois todas as colunas foram mapeadas como *string*.\n",
    "Nesse notebook iremos transformar os dados da coluna *value* em formato JSON para formato tabular utilizando a função *from_json* do Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente\n",
    "\n",
    "O código abaixo adiciona a **raiz** do projeto, que contém códigos e dados necessários para o \"Hands on\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/bigdata/jupyterhub'\n",
    "\n",
    "import sys\n",
    "sys.path.append(root)\n",
    "\n",
    "wd = '/delta'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O trecho de código abaixo prepara o ambiente, carregando códigos auxiliares e dados de configuração.O código disponível no pacote *commom.utils* na classe *DataframeUtils* contém vários métodos que facilitam a leitura e escrita dos dados do Postgres. A classe *DataframeUtils* também inicia uma instância do Apache Spark com o Delta Lake integrado ao Spark.\n",
    "\n",
    "Já o arquivo *config.yaml* tem os dados de acesso ao Postgres e Kafka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "from common.utils import DataframeUtils\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "config = yaml.safe_load(open('../config.yaml'))\n",
    "dfu = DataframeUtils(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O trecho abaixo cria o Dataframe no formato **delta** de clientes apontando para o diretório do HDFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clientes = dfu. \\\n",
    "  spark(). \\\n",
    "  read. \\\n",
    "  format('delta'). \\\n",
    "  load(f'{wd}/data/clientes-bronze')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de iniciar a extração dos dados, vamos visualizar como eles estão armazenados na *bronze table*.\n",
    "\n",
    "```\n",
    "[ ]: clientes.select('value').limit(1).show(truncate=False)\n",
    "+---------------------------------------------------------------------------------------------------------+\n",
    "|value                                                                                                    |\n",
    "+---------------------------------------------------------------------------------------------------------+\n",
    "|{\"city\":\"SANTA TEREZA DE\",\"client_id\":\"306162244\",\"cnae_id\":\"47.29-6-02\",\"defaulting\":false,\"state\":\"GO\"}|\n",
    "+---------------------------------------------------------------------------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------+\n",
      "|value                                                                                                    |\n",
      "+---------------------------------------------------------------------------------------------------------+\n",
      "|{\"city\":\"SANTA TEREZA DE\",\"client_id\":\"306162244\",\"cnae_id\":\"47.29-6-02\",\"defaulting\":false,\"state\":\"GO\"}|\n",
      "+---------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clientes.select('value').limit(1).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O trecho abaixo cria uma view temporária para executar códigos com o Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clientes.createOrReplaceTempView('clientes_bronze')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que já sabemos como os dados estão armanenados, podemos realizar a extração das propriedades JSON contidas no campo *value* utilizando a função from_json do Spark. Nesse ponto já vamos alterar o tipo da coluna *defaulting* para boolean.\n",
    "\n",
    "A extração dos dados segue o mesmo padrão para todas as colunas:\n",
    "```\n",
    "from_json(value, '<nome do campo> <tipo do dado>')\n",
    "```\n",
    "\n",
    "A função *from_json* retorna um *Row*, por isso precisamos extrair o campo que queremos, o código fica assim:\n",
    "```\n",
    "from_json(value, '<nome do campo> <tipo do dado>')[<nome do campo>] as <nome do campo>\n",
    "```\n",
    "\n",
    "Na consulta abaixo aplicamos esse padrão de extração em todas as colunas de clientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: string (nullable = true)\n",
      " |-- client_id: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- cnae_id: string (nullable = true)\n",
      " |-- defaulting: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>key</th><th>client_id</th><th>city</th><th>state</th><th>cnae_id</th><th>defaulting</th><th>timestamp</th></tr>\n",
       "<tr><td>232</td><td>58811879</td><td>JOAO PESSOA</td><td>PB</td><td>47.71-7-01</td><td>false</td><td>2020-06-29 18:16:...</td></tr>\n",
       "<tr><td>381</td><td>58813621</td><td>SAO JOSE DO PIA</td><td>PI</td><td>4771701</td><td>false</td><td>2020-06-29 18:16:...</td></tr>\n",
       "<tr><td>562</td><td>58813754</td><td>TERESINA</td><td>PI</td><td>4771701</td><td>false</td><td>2020-06-29 18:16:...</td></tr>\n",
       "<tr><td>624</td><td>58818233</td><td>SANTAREM</td><td>PA</td><td>47.71-7-01</td><td>false</td><td>2020-06-29 18:16:...</td></tr>\n",
       "<tr><td>812</td><td>21433734</td><td>AURORA</td><td>CE</td><td>4771704</td><td>false</td><td>2020-06-29 18:16:...</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---+---------+---------------+-----+----------+----------+--------------------+\n",
       "|key|client_id|           city|state|   cnae_id|defaulting|           timestamp|\n",
       "+---+---------+---------------+-----+----------+----------+--------------------+\n",
       "|232| 58811879|    JOAO PESSOA|   PB|47.71-7-01|     false|2020-06-29 18:16:...|\n",
       "|381| 58813621|SAO JOSE DO PIA|   PI|   4771701|     false|2020-06-29 18:16:...|\n",
       "|562| 58813754|       TERESINA|   PI|   4771701|     false|2020-06-29 18:16:...|\n",
       "|624| 58818233|       SANTAREM|   PA|47.71-7-01|     false|2020-06-29 18:16:...|\n",
       "|812| 21433734|         AURORA|   CE|   4771704|     false|2020-06-29 18:16:...|\n",
       "+---+---------+---------------+-----+----------+----------+--------------------+"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dfu.spark().sql(\"\"\"\n",
    "select \n",
    "  key\n",
    ", from_json(value, 'client_id string')['client_id'] as client_id\n",
    ", from_json(value, 'city string')['city'] as city\n",
    ", from_json(value, 'state string')['state'] as state\n",
    ", from_json(value, 'cnae_id string')['cnae_id'] as cnae_id\n",
    ", from_json(value, 'defaulting string')['defaulting'] as defaulting\n",
    ", max(timestamp) as timestamp\n",
    "from clientes_bronze\n",
    "group by 1,2,3,4,5,6\n",
    "\"\"\")\n",
    "\n",
    "df.printSchema()\n",
    "df.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O trecho abaixo escreve no HDFS em formato delta o resultado da consulta acima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df. \\\n",
    "  write. \\\n",
    "  mode('overwrite'). \\\n",
    "  format('delta'). \\\n",
    "  save(f'{wd}/data/clientes-silver')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos realizar os mesmos passos para os dados de pedidos. A primeira etapa é criar o Dataframe apontando para o diretório no HDFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pedidos = dfu. \\\n",
    "  spark(). \\\n",
    "  read. \\\n",
    "  format('delta'). \\\n",
    "  load(f'{wd}/data/pedidos-bronze')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos visualizar como os dados estão armazenados na *bronze table*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------+\n",
      "|value                                                                                                        |\n",
      "+-------------------------------------------------------------------------------------------------------------+\n",
      "|{\"client_id\":\"20513391\",\"order_date\":\"2019-08-05T20:10:00.000Z\",\"order_id\":\"2902005913\",\"salesman_id\":\"2902\"}|\n",
      "+-------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pedidos.select('value').limit(1).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O trecho abaixo cria a *temp view* para executar consultas usando o Spark SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pedidos.createOrReplaceTempView('pedidos_bronze')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E por fim, a consulta de extração/transformação dos dados de pedidos.\n",
    "Veja que estamos transformando a coluna **order_date** para o tipo *date* e **order_amount** para o tipo *float*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: string (nullable = true)\n",
      " |-- client_id: string (nullable = true)\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- order_date: date (nullable = true)\n",
      " |-- order_amount: float (nullable = true)\n",
      " |-- salesman_id: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>key</th><th>client_id</th><th>order_id</th><th>order_date</th><th>order_amount</th><th>salesman_id</th></tr>\n",
       "<tr><td>0</td><td>20513391</td><td>2902005913</td><td>2019-08-05</td><td>null</td><td>2902</td></tr>\n",
       "<tr><td>1</td><td>20513391</td><td>2902005912</td><td>2019-08-05</td><td>1613.644</td><td>2902</td></tr>\n",
       "<tr><td>2</td><td>20513391</td><td>2503005207</td><td>2019-10-03</td><td>745.937</td><td>2503</td></tr>\n",
       "<tr><td>3</td><td>20513391</td><td>2503004969</td><td>2019-07-04</td><td>1507.87</td><td>2503</td></tr>\n",
       "<tr><td>4</td><td>20513391</td><td>2503005208</td><td>2019-10-03</td><td>null</td><td>2503</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---+---------+----------+----------+------------+-----------+\n",
       "|key|client_id|  order_id|order_date|order_amount|salesman_id|\n",
       "+---+---------+----------+----------+------------+-----------+\n",
       "|  0| 20513391|2902005913|2019-08-05|        null|       2902|\n",
       "|  1| 20513391|2902005912|2019-08-05|    1613.644|       2902|\n",
       "|  2| 20513391|2503005207|2019-10-03|     745.937|       2503|\n",
       "|  3| 20513391|2503004969|2019-07-04|     1507.87|       2503|\n",
       "|  4| 20513391|2503005208|2019-10-03|        null|       2503|\n",
       "+---+---------+----------+----------+------------+-----------+"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dfu.spark().sql(\"\"\"\n",
    "select \n",
    "  key\n",
    ", from_json(value, 'client_id string')['client_id'] as client_id\n",
    ", from_json(value, 'order_id string')['order_id'] as order_id\n",
    ", from_json(value, 'order_date date')['order_date'] as order_date\n",
    ", from_json(value, 'order_amount float')['order_amount'] as order_amount\n",
    ", from_json(value, 'salesman_id string')['salesman_id'] as salesman_id\n",
    "from pedidos_bronze\n",
    "\"\"\")\n",
    "\n",
    "df.printSchema()\n",
    "df.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O trecho abaixo escreve o resultado da consulta de pedidos no HDFS em formato delta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df. \\\n",
    "  write. \\\n",
    "  mode('overwrite'). \\\n",
    "  format('delta'). \\\n",
    "  save(f'{wd}/data/pedidos-silver')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício\n",
    "\n",
    "Agora vamos colocar em prática o que aprendemos sobre a extração de dados.\n",
    "Crie um código para extrair os dados de itens de pedidos e realizar as devidas alterações dos tipos de dados.\n",
    "De forma geral, o código deverá realizar as seguintes etapas:\n",
    "\n",
    "1. Criar o Dataframe apontando para o HDFS (/delta/data/itens-bronze)\n",
    "2. Visualizar como os dados estão armazenados na tabela bronze.\n",
    "3. Realizar a extração usando o Spark SQL.\n",
    "4. Escrever os novos dados em /delta/data/itens-silver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comece criando o dataframe\n",
    "itens = dfu. \\\n",
    "  spark(). \\\n",
    "  read. \\\n",
    "  format('delta'). \\\n",
    "  load(f'{wd}/data/itens-bronze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|value                                                                                                                                                                                                           |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|{\"client_id\":\"20513391\",\"items_count\":1,\"list_price\":5.0205,\"order_date\":\"2019-07-04T04:00:00.000Z\",\"order_id\":\"2503004970\",\"product_id\":\"11925\",\"sale_price\":5.0205,\"salesman_id\":\"2503\",\"supplier_id\":\"11967\"}|\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Veja como os dados estão armazenados\n",
    "itens.select('value').limit(1).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie uma temp view\n",
    "itens.createOrReplaceTempView('itens_bronze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: string (nullable = true)\n",
      " |-- client_id: string (nullable = true)\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- order_date: date (nullable = true)\n",
      " |-- items_count: integer (nullable = true)\n",
      " |-- list_price: float (nullable = true)\n",
      " |-- sale_price: float (nullable = true)\n",
      " |-- salesman_id: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- supplier_id: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>key</th><th>client_id</th><th>order_id</th><th>order_date</th><th>items_count</th><th>list_price</th><th>sale_price</th><th>salesman_id</th><th>product_id</th><th>supplier_id</th></tr>\n",
       "<tr><td>0</td><td>20513391</td><td>2503004970</td><td>2019-07-04</td><td>1</td><td>5.0205</td><td>5.0205</td><td>2503</td><td>11925</td><td>11967</td></tr>\n",
       "<tr><td>1</td><td>20513391</td><td>2503004969</td><td>2019-07-04</td><td>40</td><td>1.4574</td><td>1.3117</td><td>2503</td><td>18075</td><td>6000</td></tr>\n",
       "<tr><td>2</td><td>20513391</td><td>2503004969</td><td>2019-07-04</td><td>30</td><td>1.8989</td><td>1.5382</td><td>2503</td><td>18083</td><td>6000</td></tr>\n",
       "<tr><td>3</td><td>20513391</td><td>2503004969</td><td>2019-07-04</td><td>48</td><td>0.9069</td><td>0.7346</td><td>2503</td><td>18103</td><td>6000</td></tr>\n",
       "<tr><td>4</td><td>20513391</td><td>2902005913</td><td>2019-08-05</td><td>1</td><td>3.2</td><td>3.2</td><td>2902</td><td>210157</td><td>11265</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---+---------+----------+----------+-----------+----------+----------+-----------+----------+-----------+\n",
       "|key|client_id|  order_id|order_date|items_count|list_price|sale_price|salesman_id|product_id|supplier_id|\n",
       "+---+---------+----------+----------+-----------+----------+----------+-----------+----------+-----------+\n",
       "|  0| 20513391|2503004970|2019-07-04|          1|    5.0205|    5.0205|       2503|     11925|      11967|\n",
       "|  1| 20513391|2503004969|2019-07-04|         40|    1.4574|    1.3117|       2503|     18075|       6000|\n",
       "|  2| 20513391|2503004969|2019-07-04|         30|    1.8989|    1.5382|       2503|     18083|       6000|\n",
       "|  3| 20513391|2503004969|2019-07-04|         48|    0.9069|    0.7346|       2503|     18103|       6000|\n",
       "|  4| 20513391|2902005913|2019-08-05|          1|       3.2|       3.2|       2902|    210157|      11265|\n",
       "+---+---------+----------+----------+-----------+----------+----------+-----------+----------+-----------+"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realize a extração usando o Spark SQL\n",
    "dfi = dfu.spark().sql(\"\"\"\n",
    "select \n",
    "  key\n",
    ", from_json(value, 'client_id string')['client_id'] as client_id\n",
    ", from_json(value, 'order_id string')['order_id'] as order_id\n",
    ", from_json(value, 'order_date date')['order_date'] as order_date\n",
    ", from_json(value, 'items_count integer')['items_count'] as items_count\n",
    ", from_json(value, 'list_price float')['list_price'] as list_price\n",
    ", from_json(value, 'sale_price float')['sale_price'] as sale_price\n",
    ", from_json(value, 'salesman_id string')['salesman_id'] as salesman_id\n",
    ", from_json(value, 'product_id string')['product_id'] as product_id\n",
    ", from_json(value, 'supplier_id string')['supplier_id'] as supplier_id\n",
    "from itens_bronze\n",
    "\"\"\")\n",
    "\n",
    "dfi.printSchema()\n",
    "dfi.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escreva o resultado em /delta/data/itens-silver\n",
    "dfi. \\\n",
    "  write. \\\n",
    "  mode('overwrite'). \\\n",
    "  format('delta'). \\\n",
    "  save(f'{wd}/data/itens-silver')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
